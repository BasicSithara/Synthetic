{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJy23UcOU0zu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omulfPDD-nUt",
        "outputId": "0dc163a8-edcc-4b7f-8610-38aa79de7187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-25 05:21:14--  https://raw.githubusercontent.com/SreeBhagya-S/Synthetic-Manglish-Corpus/main/Datasets/amazon_fullReviews.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44354977 (42M) [text/plain]\n",
            "Saving to: ‘amazon_fullReviews.csv’\n",
            "\n",
            "amazon_fullReviews.   0%[                    ]       0  --.-KB/s               "
          ]
        }
      ],
      "source": [
        "# Downloading datasets\n",
        "!rm -rf t*\n",
        "!wget https://raw.githubusercontent.com/SreeBhagya-S/Synthetic-Manglish-Corpus/main/Datasets/amazon_fullReviews.csv\n",
        "!wget https://raw.githubusercontent.com/SreeBhagya-S/Synthetic-Manglish-Corpus/main/Datasets/amazon_cm_token.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxTRLtCrVCNJ"
      },
      "outputs": [],
      "source": [
        "df_reviews = pd.read_csv('/content/amazon_fullReviews.csv',  sep=',')\n",
        "df_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "v1K82MlhVD6W",
        "outputId": "eb9c132b-0c0f-47ca-b4b1-ec48adbf40af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           u                                         eng_tokens  \\\n",
              "0          0  'this', 'product', 'so', 'far', 'has', 'not', ...   \n",
              "1          1  'great', 'for', 'beginner', 'or', 'experienced...   \n",
              "2          2  'inexpensive', 'tablet', 'for', 'him', 'to', '...   \n",
              "3          3  'ive', 'had', 'my', 'fire', 'hd', '8', 'two', ...   \n",
              "4          4  'i', 'bought', 'this', 'for', 'my', 'grand', '...   \n",
              "...      ...                                                ...   \n",
              "34654  34654  'this', 'is', 'not', 'appreciably', 'faster', ...   \n",
              "34655  34655  'amazon', 'should', 'include', 'this', 'charge...   \n",
              "34656  34656  'love', 'my', 'kindle', 'fire', 'but', 'i', 'a...   \n",
              "34657  34657  'i', 'was', 'surprised', 'to', 'find', 'it', '...   \n",
              "34658  34658  'to', 'spite', 'the', 'fact', 'that', 'i', 'ha...   \n",
              "\n",
              "                                              mal_tokens  \\\n",
              "0      'ഈ', 'ഉൽപ്പന്നം', 'ഇതുവരെ', 'നിരാശപ്പെടുത്തിയി...   \n",
              "1      'തുടക്കക്കാരനോ', 'പരിചയസമ്പന്നനോ', 'ആയ', 'വ്യക...   \n",
              "2      'അയാൾക്ക്', 'ഉപയോഗിക്കാനും', 'പഠിക്കാനുമുള്ള',...   \n",
              "3      'എന്റെ', 'ഫയർ', 'എച്ച്ഡി', '8', 'ഇപ്പോൾ', 'രണ്...   \n",
              "4      'എന്റെ', 'കൊച്ചുമകൾ', 'സന്ദർശിക്കാൻ', 'വരുമ്പോ...   \n",
              "...                                                  ...   \n",
              "34654  'എന്റെ', 'കിൻഡിൽ', 'കിൻഡിൽ', 'ഫയർ', 'കിൻഡിൽ', ...   \n",
              "34655  'കിൻഡിലിനൊപ്പം', 'ആമസോൺ', 'ഈ', 'ചാർജർ', 'ഉൾപ്പ...   \n",
              "34656  'എന്റെ', 'കിൻഡിൽ', 'ഫയർ', 'ഇഷ്ടപ്പെടുന്നു', 'പ...   \n",
              "34657  'ഒരു', 'തരത്തിലുള്ള', 'ചാർജിംഗ്', 'കോഡുകളുമായു...   \n",
              "34658  'ആമസോണിനെ', 'കുറിച്ചും', 'ആന്തിംഗിനെ', 'കുറിച്...   \n",
              "\n",
              "                                               cm_tokens  \n",
              "0      [\" 'and'\", \" 'product'\", \" 'ഇതുവരെ'\", \" 'നിരാശ...  \n",
              "1      [\" 'beginner'\", \" 'experienced'\", \" 'or'\", \" '...  \n",
              "2      [\"'അയാൾക്ക്'\", \" 'ഉപയോഗിക്കാനും'\", \" 'പഠിക്കാന...  \n",
              "3      [\"'എന്റെ'\", \" 'ipad'\", \" 'എച്ച്ഡി'\", \" '8'\", \"...  \n",
              "4      [\"'എന്റെ'\", \" 'daughter'\", \" 'സന്ദർശിക്കാൻ'\", ...  \n",
              "...                                                  ...  \n",
              "34654  [\"'എന്റെ'\", \" 'kindle'\", \" 'കിൻഡിൽ'\", \" 'fire'...  \n",
              "34655  [\"'കിൻഡിലിനൊപ്പം'\", \"'amazon'\", \" 'ഈ'\", \" 'ചാർ...  \n",
              "34656  [\"'എന്റെ'\", \" 'kindle'\", \" 'fire'\", \" 'ഇഷ്ടപ്പ...  \n",
              "34657  [\" 'and'\", \" 'type'\", \" 'ചാർജിംഗ്'\", \" 'കോഡുകള...  \n",
              "34658  [\"'ആമസോണിനെ'\", \" 'കുറിച്ചും'\", \" 'ആന്തിംഗിനെ'\"...  \n",
              "\n",
              "[34659 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b63bf9cf-f1dd-4967-a6d4-1f37f4e2c9cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>u</th>\n",
              "      <th>eng_tokens</th>\n",
              "      <th>mal_tokens</th>\n",
              "      <th>cm_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>'this', 'product', 'so', 'far', 'has', 'not', ...</td>\n",
              "      <td>'ഈ', 'ഉൽപ്പന്നം', 'ഇതുവരെ', 'നിരാശപ്പെടുത്തിയി...</td>\n",
              "      <td>[\" 'and'\", \" 'product'\", \" 'ഇതുവരെ'\", \" 'നിരാശ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>'great', 'for', 'beginner', 'or', 'experienced...</td>\n",
              "      <td>'തുടക്കക്കാരനോ', 'പരിചയസമ്പന്നനോ', 'ആയ', 'വ്യക...</td>\n",
              "      <td>[\" 'beginner'\", \" 'experienced'\", \" 'or'\", \" '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>'inexpensive', 'tablet', 'for', 'him', 'to', '...</td>\n",
              "      <td>'അയാൾക്ക്', 'ഉപയോഗിക്കാനും', 'പഠിക്കാനുമുള്ള',...</td>\n",
              "      <td>[\"'അയാൾക്ക്'\", \" 'ഉപയോഗിക്കാനും'\", \" 'പഠിക്കാന...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>'ive', 'had', 'my', 'fire', 'hd', '8', 'two', ...</td>\n",
              "      <td>'എന്റെ', 'ഫയർ', 'എച്ച്ഡി', '8', 'ഇപ്പോൾ', 'രണ്...</td>\n",
              "      <td>[\"'എന്റെ'\", \" 'ipad'\", \" 'എച്ച്ഡി'\", \" '8'\", \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>'i', 'bought', 'this', 'for', 'my', 'grand', '...</td>\n",
              "      <td>'എന്റെ', 'കൊച്ചുമകൾ', 'സന്ദർശിക്കാൻ', 'വരുമ്പോ...</td>\n",
              "      <td>[\"'എന്റെ'\", \" 'daughter'\", \" 'സന്ദർശിക്കാൻ'\", ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34654</th>\n",
              "      <td>34654</td>\n",
              "      <td>'this', 'is', 'not', 'appreciably', 'faster', ...</td>\n",
              "      <td>'എന്റെ', 'കിൻഡിൽ', 'കിൻഡിൽ', 'ഫയർ', 'കിൻഡിൽ', ...</td>\n",
              "      <td>[\"'എന്റെ'\", \" 'kindle'\", \" 'കിൻഡിൽ'\", \" 'fire'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34655</th>\n",
              "      <td>34655</td>\n",
              "      <td>'amazon', 'should', 'include', 'this', 'charge...</td>\n",
              "      <td>'കിൻഡിലിനൊപ്പം', 'ആമസോൺ', 'ഈ', 'ചാർജർ', 'ഉൾപ്പ...</td>\n",
              "      <td>[\"'കിൻഡിലിനൊപ്പം'\", \"'amazon'\", \" 'ഈ'\", \" 'ചാർ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34656</th>\n",
              "      <td>34656</td>\n",
              "      <td>'love', 'my', 'kindle', 'fire', 'but', 'i', 'a...</td>\n",
              "      <td>'എന്റെ', 'കിൻഡിൽ', 'ഫയർ', 'ഇഷ്ടപ്പെടുന്നു', 'പ...</td>\n",
              "      <td>[\"'എന്റെ'\", \" 'kindle'\", \" 'fire'\", \" 'ഇഷ്ടപ്പ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34657</th>\n",
              "      <td>34657</td>\n",
              "      <td>'i', 'was', 'surprised', 'to', 'find', 'it', '...</td>\n",
              "      <td>'ഒരു', 'തരത്തിലുള്ള', 'ചാർജിംഗ്', 'കോഡുകളുമായു...</td>\n",
              "      <td>[\" 'and'\", \" 'type'\", \" 'ചാർജിംഗ്'\", \" 'കോഡുകള...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34658</th>\n",
              "      <td>34658</td>\n",
              "      <td>'to', 'spite', 'the', 'fact', 'that', 'i', 'ha...</td>\n",
              "      <td>'ആമസോണിനെ', 'കുറിച്ചും', 'ആന്തിംഗിനെ', 'കുറിച്...</td>\n",
              "      <td>[\"'ആമസോണിനെ'\", \" 'കുറിച്ചും'\", \" 'ആന്തിംഗിനെ'\"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34659 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b63bf9cf-f1dd-4967-a6d4-1f37f4e2c9cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b63bf9cf-f1dd-4967-a6d4-1f37f4e2c9cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b63bf9cf-f1dd-4967-a6d4-1f37f4e2c9cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_tokens= pd.read_csv('/content/amazon_cm_token.csv',  sep=',')\n",
        "df_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNYeRqpaVl6v",
        "outputId": "aa00e366-f990-48f0-c545-d13e371ffaa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from indic-nlp-library) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from indic-nlp-library) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->indic-nlp-library) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx-argparse->indic-nlp-library) (3.5.4)\n",
            "Requirement already satisfied: docutils<0.18 in /usr/local/lib/python3.8/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.25.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.9)\n",
            "Installing collected packages: morfessor, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install indic-nlp-library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_31fIOVHNvaW"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgjyz7a6NSAM"
      },
      "outputs": [],
      "source": [
        "def e_tokenize(es):\n",
        "  es=es.lower()\n",
        "  es= es.translate(str.maketrans('', '', string.punctuation))\n",
        "  e_token=[]\n",
        "  #indic_string=clean_text(text)\n",
        " \n",
        "  for t in indic_tokenize.trivial_tokenize(es): \n",
        "    #print(t)\n",
        "    #e_token=en_tokens.split(',')\n",
        "    e_token.append(t)\n",
        "    #df_e_tokens.loc[len(df_e_tokens)] = e_token\n",
        "  return e_token\n",
        "\n",
        "def m_tokenize(ms):\n",
        "  input_text = ms.translate(str.maketrans('', '', string.punctuation))\n",
        "  factory=IndicNormalizerFactory()\n",
        "  normalizer=factory.get_normalizer(\"ml\",remove_nuktas=True)\n",
        "  output_text=normalizer.normalize(input_text)\n",
        "  m_token=[]\n",
        "  for t in indic_tokenize.trivial_tokenize(output_text): \n",
        "    m_token.append(t)\n",
        "  return(m_token)\n",
        "\n",
        "def cmtoken_clean(words):\n",
        "  step1 = words.replace(\"`\", \"\")\n",
        "  step2 = step1.replace('\"', '')\n",
        "  step3 = step2.replace('\" ','')\n",
        "  step4 = step3.replace(',  ',',')\n",
        "  return step3.strip()\n",
        "\n",
        "def t_tokenize(ts):\n",
        "  ts=ts.lower()\n",
        "  ts= ts.translate(str.maketrans('', '', string.punctuation))\n",
        "  t_token=[]\n",
        "  #indic_string=clean_text(text)\n",
        " \n",
        "  for t in indic_tokenize.trivial_tokenize(ts): \n",
        "    #print(t)\n",
        "    #e_token=en_tokens.split(',')\n",
        "    t_token.append(t)\n",
        "  return t_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTNae207VJnm"
      },
      "outputs": [],
      "source": [
        "refs = []\n",
        "for i in range(len(df_reviews)):\n",
        "  row=df_reviews.english_reviews[i]\n",
        "  refs.append(e_tokenize(row))\n",
        "\n",
        "\n",
        "mal = []\n",
        "for i in range(len(df_reviews)):\n",
        "  row=df_reviews.malayalam_reviews[i]\n",
        "  mal.append(m_tokenize(row))\n",
        "\n",
        "cm = []\n",
        "for i in range(len(df_reviews.cm_reviews)):\n",
        "  row=df_reviews.cm_reviews[i]\n",
        "  cm.append(t_tokenize(row))\n",
        "\n",
        "trans = []\n",
        "for i in range(len(df_reviews.transliterated_cm_reviews)):\n",
        "  row=df_reviews.transliterated_cm_reviews[i]\n",
        "  trans.append(t_tokenize(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXVSTcIlVQf-",
        "outputId": "467e0896-a904-4d26-b1e9-c7145088ac1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Collecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 evaluate-0.4.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDN81REEVS1-",
        "outputId": "5c77c0f2-4a16-4a53-b339-6bb174d90f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.12-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bert_score) (2.25.1)\n",
            "Collecting transformers>=3.0.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from bert_score) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bert_score) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.8/dist-packages (from bert_score) (4.64.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bert_score) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from bert_score) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bert_score) (1.13.1+cu116)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->bert_score) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert_score) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert_score) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert_score) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert_score) (0.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert_score) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert_score) (2022.6.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bert_score) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bert_score) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bert_score) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bert_score) (1.26.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n",
            "Installing collected packages: tokenizers, transformers, bert_score\n",
            "Successfully installed bert_score-0.3.12 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IoeHsdspcq1u",
        "outputId": "6f20f78f-2b62-40e1-c147-934c5cd8ecfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.12'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# check your installation\n",
        "import bert_score\n",
        "bert_score.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwAiQDnectIy"
      },
      "outputs": [],
      "source": [
        "# hide the loading messages\n",
        "import logging\n",
        "import transformers\n",
        "import json\n",
        "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.modeling_utils.logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtzOLAZRcyE6"
      },
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "from transformers import BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O_zexc0e3g1"
      },
      "outputs": [],
      "source": [
        "#################################### BERT Score between Mal and CM reviews #########################################################\n",
        "f1_scores=[]\n",
        "p_scores=[]\n",
        "r_scores=[]\n",
        "for i in range(len(df_reviews)):\n",
        "  ts=0.6+(i*0.01)\n",
        "  cands=cm[i]\n",
        "  refs1=mal[i]\n",
        "  p=len(cands)\n",
        "  t=len(refs1)\n",
        "  if p<t:\n",
        "    cands.extend([' '] * (t-p))\n",
        "  elif t<p:\n",
        "    refs1.extend([' '] * (p-t))\n",
        "  P, R, F1 = score(cands, refs1, model_type=\"bert-base-multilingual-cased\")\n",
        "  print(\"\\n***************************************** In Row \",i,\" ************************************************************\\n\")\n",
        "  f1_mean='{}'.format(F1.mean())\n",
        "  #print(f1_mean)\n",
        "  f1_scores += [f1_mean]\n",
        "  p_mean='{}'.format(P.mean())\n",
        "  #print(Precision mean)\n",
        "  p_scores += [p_mean]\n",
        "  r_mean='{}'.format(R.mean())\n",
        "  #print(REcall_mean)\n",
        "  r_scores += [r_mean]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZGBQFlx6O29"
      },
      "outputs": [],
      "source": [
        "f1=[eval(i) for i in  f1_scores]\n",
        "p=[eval(i) for i in  p_scores]\n",
        "r=[eval(i) for i in  r_scores]\n",
        "print(\"\\n\",f1,\"\\n\",p,\"\\n\",r,\"\\n\")\n",
        "print(len(f1),\"\\n\")\n",
        "print(len(p),\"\\n\")\n",
        "print(len(r),\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYSYhH6Od0pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed663eab-56d8-4c58-ea03-bd7c3f8bf8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty File Created Successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "with open('/content/bert_score_mal_cm.csv', 'w') as file:\n",
        "   pass \n",
        "print(\"Empty File Created Successfully\")\n",
        "a = np.array(f1)\n",
        "b = np.array(p)\n",
        "c=np.array(r)\n",
        "df = pd.DataFrame({\"f1\" : a, \"precision\" : b,\"recall\":c})\n",
        "df.to_csv(\"bert_score_mal_cm.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdlnYYb0hGdY"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "print(\"\\n\\nF1 Score: \",mean([eval(i) for i in  f1_scores]),\"\\n\\nPrecision Score: \",mean([eval(i) for i in  p_scores]),\"\\n\\nRecall Score: \",mean([eval(i) for i in  r_scores]),\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}